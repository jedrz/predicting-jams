\documentclass[a4paper,12pt]{mwart}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{color}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{positioning,shapes,shadows,arrows}

\lstset{
  basicstyle=\scriptsize
}

\newcommand{\TODO}[1]{\textcolor{blue}{TODO: #1 \\}}
\newcommand{\ang}[1]{ang.~{\itshape #1}}

% http://tex.stackexchange.com/questions/83440/inputenc-error-unicode-char-u8-not-set-up-for-use-with-latex
\DeclareUnicodeCharacter{00A0}{~}

\begin{document}

\title{Predicting Jams\\%
{\large czyli model prognozujący tworzenie się korków samochodowych} }

\author{Łukasz Jędrzejewski \and Artur Sawicki}

\maketitle

\section{Opis projektu}
W ramach projektu realizowaliśmy zadanie polegające na zbudowaniu modelu prognozującego tworzenie się korków na podstawie historychnych obserwacji. Zadanie opiera się na zadaniu ze strony \href{http://tunedit.org/challenge/IEEE-ICDM-2010/jams}{tunedit.org}.

Do realizacji celów zadania użyliśmy bazy danych \href{https://www.postgresql.org/}{PostgreSQL} rozszerzonej o dodatek umożliwiający pracę z danymi przestrzennymi \href{http://postgis.net/}{PostGIS}. Aby ułatwić pracę na różnych maszynach, baza danych wraz z rozszerzeniem zainstalowana jest na kontenerze typu \href{https://www.docker.com/}{docker}. Skrypty odpowiadające za stworzenie schematu w bazie danych, przetwarzanie i wizualizację danych oraz właściwe obliczenia napisaliśmy w języku \href{https://www.python.org/}{python}.

\section{Opis problemu}
\subsection{Wprowadzenie}
Stacje radiowe wpadły na pomysł zbierania informacji dotyczących zatłoczenia ulic oraz przekazywanie ich do kierowców, w celu umożliwienia im omijania nieprzejezdnych dróg. Takie dane można użyć też w inny sposób - na ich podstawie można przewidzieć, gdzie mogą pojawić się kolejne korki, bazując na początkowym stopniu zatłoczenia ulic. Tego właśnie dotyczy zadanie.

\subsection{Dane}
Dane użyte w zadaniu wygenerowane zostały z jedno-godzinnych symulacji. Każda z nich zaczynała się prawie pustą siecią dróg, do której dodawane są samochody, z losowo wybranym punktem startu i docelowym.

Na początku każdej symulacji 5 losowych odcinków dróg (2 główne i 3 mniejsze) zostawało usuniętych z grafu imitując roboty drogowe. Jako dane wejściowe algorytm dostaje identyfikatory 5 usuniętych dróg oraz sekwencję identyfikatorów dróg, na których korek pojawił się w ciągu pierwszych 20 minut symulacji. Zadaniem jest przewidzenie korków w następnych 40 minutach.

Odcinek uznajemy za zakorkowany kiedy średnia prędkość w ciągu ostatnich 6 minut nie przekroczyła 5km/h, a liczba samochodów jaka przejchała lub znajduje się na nim jest większa niż 10.

Zbiór treningowy i zbiór testowy zawierają po 5000 próbek, z których każda jest pojedynczą symulacją. Dane treningowe zawierają pierwsze 20 minut symulacji oraz kolejne 40 minut, natomiast dane testowe - tylko pierwsze 20 minut.

Dostępny jest także graf ulic.

Na~koniec należy wspomnieć, że~zgromadzone dane dotyczą Warszawy.

\subsection{Wizualizacja}
Powyższe dane zwizualizowaliśmy. Nie miało to wpływu na predykcję, jednak pozwoliło nam obejrzeć dane, z którymi pracowaliśmy. Poniżej prezentujemy efekty.

\begin{figure}[h]
\centerline{\includegraphics[width=\textwidth]{figures/jams.png}}
\caption{Rysunek przedstawia wszystkie korki znajdujące się w danych treningowych. Litera f oznacza korek z pierwszych 20 minut, litera s - z~kolejnych 40. Numery wyznaczają kolejność korków.}
\end{figure}

\begin{figure}[h]
\centerline{\includegraphics[width=\textwidth]{figures/map.png}}
\caption{Rysunek pokazuje wszystkie drogi zawarte w grafie.}
\end{figure}

\section{Model danych}

\begin{figure}[H]
\centerline{\includegraphics[width=\textwidth]{figures/diagram.png}}
\caption{Model danych zaprezentowany na diagramie relacji.}
\end{figure}

\section{Predykcja}

\subsection{Dane}

Udostępniony zbiór treningowy zawierających 5000 symulacji podzieliśmy na~dwa zbiór treningowy składający się z~4500 symulacji oraz zbiór testowy zawierających 500 przykładów. Nie zdecydowaliśmy się skorzystać z~zamieszczonego na~stronie zadania zbioru testowego, ponieważ zawierał on~tylko dane z~20 pierwszych minut. W~związku z~tym do~oceny zbudowanego modelu używamy części danych treningowych.

Po~wizualizacji kilkunastu korków, okazało się że~mają one raczej charakter globalny. Nie widać wyraźnej reguły, że~korki w~pewnym segmencie ulicy, przeniosą się na~segment, który jest nieopodal. Tak może się w~ogóle nie stać. W~związku z~tym wymusiło to~przemyślenie rozwiązania, które nie będzie opierało się przede wszystkim na~aspekcie geograficznym, a~w~dużym stopniu korzystało ze~zbioru treningowego.

\subsection{Ocena rozwiązania}

Do~oceny poprawności predykcji korków w~ciągu kolejnych 40~minut, wykorzystaliśmy miarę zaproponowaną przez pomysłodawców zadania. Została ona użyta do~oceny rozwiązań zgłoszonych w~trakcie trwania konkursu w~2010 roku.

Poniżej zamieściliśmy oryginalną formułę do~porównywania podobieństwa dwóch rozwiązań:

\[quality(P, T) = \frac{1}{N}\sum_{i = 1}^N Precision(P, T, i)\]

\[Precision(P, T, i) = \frac{\left | P_i \cap T_i \right |}{i}\]

\[N = \max (\left | P \right |, \left | T \right |)\]

gdzie:

\begin{itemize}
\item $P$, $T$ -- listy zawierające segmenty kolejno zakorkowanych dróg w~ciągu 40 minut,
\item $P_i$, $T_i$ -- zakorkowany segment drogi na~pozycji $i$ rozwiązania,
\item $\left | P \right |$, $\left | T \right |$ -- liczba zakorkowanych segmentów w~ciągu 40 minut.
\end{itemize}

Tak zdefiniowana formuła oceny posiada kilka cech. Najważniejszą wydaje się mocniejsze premiowanie poprawnych predykcji na~początku listy segmentów. W~szczególności, pierwszy segment będzie ma~wpływ na~ocenę wszystkich kolejnych segmentów -- zarówno w~ujęciu pozytywnym, jak i~negatywnym. Kolejną cechą jest uwzględnianie kolejności, zatem rozwiązania zawierające wszystkie dokładnie wszystkie segmenty jak rozwiązanie wzorcowe, nie otrzymają wzorcowej oceny.

\subsection{Algorytm}

W~algorytmie predykcji zakorkowanych segmentów dróg można wyróżnić dwa główne etapy:

\begin{enumerate}
\item Wybór najbardziej podobnych korków w~pierwszych 20~minutach, dla danych segmentów dróg zakorkowanych w~pierwszych 20 minutach.
\item Na~podstawie $n$ najlepszych korków z~danych treningowych predykcja liczby segmentów zakorkowanych w~ciągu 40~minut oraz zakorkowanych segmentów.
\end{enumerate}

\paragraph{Wybór korków} Dla każdego korka w~zbiorze treningowym, oceniamy jego podobieństwo (listę zakorkowanych segmentów w~pierwszych 20~minutach) do~listy zakorkowanych segmentów w~pierwszych 20~minutach dla których chcemy dokonać predykcji.

Podobieństwo obliczamy w~następujący sposób: dla każdego segmentu w~liście z~przykładu treningowego, badamy czy znajduje się on~w~liście przykładu testowego. Jeśli nie, zwiększamy podobieństwo proporcjonalnie do~odległości do~najbliższego segmentu w~liście testowej (ale ma~to~dużo mniejszy wpływ, niż gdyby się znajdował). Jeśli zaś znajduje, to~zwiększamy podobieństwo o~długość, ale pomniejszone o~różnicę pozycji w~segmentach.

Na~koniec uzyskane podobieństwo każemy proporcjonalnie do~różnicy liczby segmentów. Jeśli liczba segmentów jest identyczna, podobieństwo pozostawiamy bez zmian.

\paragraph{Właściwa predykcja} Posiadając posortowane korki pod względem podobieństwa, wybieramy pewną ich część do~budowy rozwiązania. Spośród wybranych najlepiej rokujących korków, wybieramy znowu pewną część, aby dokonać predykcji liczby zakorkowanych segmentów w~następnych 40~minutach. Odbywa się to~na~zasadzie obliczenia średniej arytmetycznej długości zakorkowanych segmentów z~pośród części korków.

W~tym momencie pozostaje do~wykonania najtrudniejsza część, czyli predykcja kolejno zakorkowanych segmentów dróg. Na~początku budujemy dwie pomocnicze struktury -- zawierające średnią pozycję segmentu w~wybranych korkach, oraz częstość występowania. Następnie musimy wybrać najlepsze segmenty do~obsadzenia na~kolejnych pozycjach przewidywanego korka. I~tak, dla każdej pozycji, wybieramy segmenty, które znajdowały się na~podobnych pozycjach (korzystając z~pomocnicznej struktury), a~następnie spośród tak wybranych pozycji, wybieramy tą, która występowała najczęściej (tu~także korzystając z~pomocniczej struktury).

\paragraph{Parametry}

W~trakcie tworzenia algorytmu wyłoniło się co~najmniej kilka parametrów.

\begin{enumerate}
\item wpływ różnicy długości segmentów na~ich podobieństwo (im~różnica większa, tym bardziej karzemy podobieństwo),
\item minimalna liczba segmentów występujących w~okolicy $i$-tej pozycji, spośród których wybierany jest najlepszy segment,
\item przesunięcie akceptowalnej pozycji dla szukanych, segmentów na podobnych pozycjach,
\item liczba najlepszych korków, spośród których dokonujemy predykcji,
\item część najlepszych korków spośród najlepszych korków do~dokonania predykcji długości,
\item czy użyty segment, powinien być usunięty po~wybraniu -- w~zadaniu segmenty się nie powtarzają, ale potencjalne użycie go~np. w~dwóch miejscach, z~których jedno jest poprawne może być lepsze niż nietrafienie na~dwóch pozycjach.
\end{enumerate}

\subsection{Wyniki}

Po~pobieżnej nastawie parametrów, udało się uzyskać średni wynik, dla zestawu 500 przykładów testowych, na~poziomie 31\%.

\subsection{Ulepszenia}

Zaproponowane rozwiązanie na~pewno nie jest bez wad, ale widzimy kilka możliwości, godnych przeprowadzenia eksperymentu:

\begin{enumerate}
\item Inny sposób porównywania listy segmentów, tak aby w~większym stopniu brał pod uwagę dane geograficzne. Na~przykład dla segmentu, który nie znajduje się w~liście segmentów testowych, można by~wyliczyć wagę na~podstawie odległości, ale tak by~odległość wzdłuż podobnych ulic była premiowana.
\item Wybrane, najlepsze korki do~predykcji, mogłyby być ważone, tak by~jeszcze bardziej podobne, miały większy wpływ na~predykcję. W~tej chwili są~traktowane na~równi.
\item Optymalizacja parametrów algorytmu, tak aby zwiększyć skuteczność. Można by~użyć jednej z~wielu metod optymalizacji oraz walidacji krzyżowej, aby nie dopasować nadmiernie modelu do~danych.
\end{enumerate}

\section{Uruchamianie}
\subsection{Baza danych}
Aby uruchomić bazę danych należy:
\begin{enumerate}
\item Zainstalować program docker dostępny na stronie \href{https://www.docker.com/}{docker.com}.
\item Uruchomić kontener zawierający bazę PostgreSQL z rozszerzeniem PostGIS:
\begin{lstlisting}
sudo docker run --name "postgis" -p 25432:5432 -d -t kartoza/postgis
\end{lstlisting}
\item Połączyć się z bazą używając polecenia psql:
\begin{lstlisting}
psql -h localhost -U docker -p 25432 -d postgres
\end{lstlisting}
\item Włączyć dodatek:
\begin{lstlisting}
create extension Postgis;
\end{lstlisting}
\item Stworzyć bazę danych:
\begin{lstlisting}
create database "predicting-jams" owner docker encoding 'UTF8' template template_postgis;
\end{lstlisting}
\item Przełączyć się na utworzoną bazę danych:
\begin{lstlisting}
\c "predicting-jams"
\end{lstlisting}
\item Stworzyć schemat (zakładamy połączenie z bazą przez psql z głównego katalogu projektu):
\begin{lstlisting}
\i sql/create.sql
\end{lstlisting}
\item (opcjonalnie) Jeżeli będzie potrzeba zrzucenia schematu:
\begin{lstlisting}
\i sql/drop.sql
\end{lstlisting}
\end{enumerate}

\subsection{Wczytywanie danych}
Aby wczytać dane należy uruchomić bazę danych, a następnie wykonać skrypt:
\begin{lstlisting}
python3 load_data.py
\end{lstlisting}

\subsection{Wizualizacja danych}
Wizualizacja danych zawarta jest w~pliku \verb+visualize.py+. Możliwe jest wybranie kilku: wyświetlenie mapy, wyświetlenie krawędzi na~mapie, czy też samych punktów, wybranie i~wyświetlenie korka.

\subsection{Predykcja}
Algorytm odpowiedzialny za~predykcję znajduje się w~pliku \verb+predict+. Dla użytkownika przeznaczone są~trzy funkcje:
\begin{enumerate}
\item \verb+predict+ -- dla danego korka, przewiduje kolejno zakorkowane segmenty dróg w~40 minutach,
\item \verb+predict_and_evaluate+ -- robi to~samo co~funkcja \verb+predict+, ale zwraca jakość rozwiązania,
\item \verb+validate_model+ -- ocenia jakość predykcji modelu.
\end{enumerate}

\section{Podsumowanie}
Zadanie pokazało jaki potencjał czai się w wykorzystywaniu przestrzennych danych i jak można używać ich do rozwiązywania szerokich zakresów problemów.

Podczas wykonywania projektu nauczyliśmy się wielu rzeczy. Mogliśmy w praktyce obejrzeć przykłady danych przestrzennych w bazie danych, czego teorię poznaliśmy podczas zajęć wykładowych. Pierwszy raz użyliśmy kontenera do uruchamiania bazy danych, co znacznie ułatwiło pracę na różnych komputerach i początkową konfigurację.

Przeprowadzony eksperyment przebiegł lepiej niż się spodziewaliśmy. Znając wyniki konkursu, z którego zadanie rozwiązywaliśmy, gdzie pierwsze miejsce miało precyzję niewiele ponad 50\%, spodziewaliśmy się wyniku nieprzekraczającego 10\%. Z radością przyjęliśmy kolejne coraz to lepsze wyniki, aż w końcu uzyskaliśmy wynik ponad 30\%, z którego jesteśmy zadowoleni.

\end{document}
